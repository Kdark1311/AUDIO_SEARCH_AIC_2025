"""
ELASTICSEARCH EXPORT SCRIPT - FIXED VERSION
Export toÃ n bá»™ index thÃ nh JSON files Ä‘á»ƒ Ä‘áº©y lÃªn GitHub
"""

import os
import json
from elasticsearch import Elasticsearch
from tqdm import tqdm


def export_index_to_files(
    host="http://localhost:9200",
    index_name="speech_index",
    output_dir="elasticsearch_data",
    batch_size=1000
):
    """
    Export Elasticsearch index thÃ nh cÃ¡c file JSON nhá»
    
    Args:
        host: Elasticsearch URL
        index_name: TÃªn index cáº§n export
        output_dir: ThÆ° má»¥c lÆ°u files (cÃ³ thá»ƒ Ä‘áº©y lÃªn GitHub)
        batch_size: Sá»‘ documents má»—i file
    """
    
    print("="*80)
    print("ğŸ“¦ ELASTICSEARCH INDEX EXPORT")
    print("="*80)
    
    # Káº¿t ná»‘i ES
    print(f"\nğŸ”Œ Äang káº¿t ná»‘i tá»›i {host}...")
    es = Elasticsearch(hosts=[host], verify_certs=False, ssl_show_warn=False)
    
    if not es.ping():
        print("âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i Elasticsearch!")
        return
    
    print("âœ… ÄÃ£ káº¿t ná»‘i")
    
    # Kiá»ƒm tra index
    if not es.indices.exists(index=index_name):
        print(f"âŒ Index '{index_name}' khÃ´ng tá»“n táº¡i!")
        return
    
    # Láº¥y mapping
    print(f"\nğŸ“‹ Äang láº¥y mapping cá»§a index '{index_name}'...")
    mapping_response = es.indices.get_mapping(index=index_name)
    
    # âœ… FIX: Convert ObjectApiResponse to dict
    mapping = dict(mapping_response)
    
    # Táº¡o thÆ° má»¥c output
    os.makedirs(output_dir, exist_ok=True)
    
    # LÆ°u mapping
    mapping_file = os.path.join(output_dir, "mapping.json")
    with open(mapping_file, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)
    print(f"âœ… ÄÃ£ lÆ°u mapping: {mapping_file}")
    
    # Äáº¿m documents
    count_result = es.count(index=index_name)
    total_docs = count_result['count']
    print(f"\nğŸ“Š Tá»•ng sá»‘ documents: {total_docs:,}")
    
    # Export documents theo batch
    print(f"\nğŸ“¤ Äang export documents (batch size: {batch_size})...")
    
    batch_num = 0
    exported = 0
    
    # Scroll API Ä‘á»ƒ láº¥y táº¥t cáº£ documents
    query = {"query": {"match_all": {}}}
    
    # Initial search
    response = es.search(
        index=index_name,
        body=query,
        scroll='2m',
        size=batch_size
    )
    
    scroll_id = response['_scroll_id']
    hits = response['hits']['hits']
    
    # Progress bar
    pbar = tqdm(total=total_docs, desc="Exporting", unit="docs")
    
    while hits:
        # LÆ°u batch hiá»‡n táº¡i
        batch_file = os.path.join(output_dir, f"batch_{batch_num:04d}.json")
        batch_data = []
        
        for hit in hits:
            # Chá»‰ láº¥y _source (bá» _id, _index, _score)
            doc = hit['_source']
            
            # âš ï¸ Bá» EMBEDDING Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c file (sáº½ táº¡o láº¡i khi import)
            if 'embedding' in doc:
                doc['embedding'] = None  # ÄÃ¡nh dáº¥u Ä‘á»ƒ táº¡o láº¡i sau
            
            batch_data.append(doc)
        
        # Ghi file
        with open(batch_file, 'w', encoding='utf-8') as f:
            json.dump(batch_data, f, ensure_ascii=False, indent=2)
        
        exported += len(hits)
        pbar.update(len(hits))
        batch_num += 1
        
        # Láº¥y batch tiáº¿p theo
        response = es.scroll(scroll_id=scroll_id, scroll='2m')
        scroll_id = response['_scroll_id']
        hits = response['hits']['hits']
    
    pbar.close()
    
    # Clear scroll
    es.clear_scroll(scroll_id=scroll_id)
    
    # LÆ°u metadata
    metadata = {
        "index_name": index_name,
        "total_documents": total_docs,
        "total_batches": batch_num,
        "batch_size": batch_size,
        "note": "embedding=None will be regenerated on import"
    }
    
    metadata_file = os.path.join(output_dir, "metadata.json")
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    print("\n" + "="*80)
    print("âœ… EXPORT HOÃ€N THÃ€NH!")
    print("="*80)
    print(f"ğŸ“ ThÆ° má»¥c output: {output_dir}")
    print(f"ğŸ“ Sá»‘ files: {batch_num + 2} (mapping + metadata + {batch_num} batches)")
    print(f"ğŸ“Š Tá»•ng documents: {exported:,}")
    print("\nğŸ’¡ BÆ°á»›c tiáº¿p theo:")
    print(f"   1. Kiá»ƒm tra thÆ° má»¥c: {output_dir}/")
    print(f"   2. Äáº©y lÃªn GitHub: git add {output_dir} && git commit && git push")
    print(f"   3. TrÃªn mÃ¡y khÃ¡c: git clone vÃ  cháº¡y import_elasticsearch.py")
    print("="*80)


if __name__ == "__main__":
    # Cáº¥u hÃ¬nh
    HOST = "http://localhost:9200"
    INDEX_NAME = "speech_index"
    OUTPUT_DIR = "elasticsearch_data"  # ThÆ° má»¥c nÃ y sáº½ Ä‘áº©y lÃªn GitHub
    
    # Cháº¡y export
    export_index_to_files(
        host=HOST,
        index_name=INDEX_NAME,
        output_dir=OUTPUT_DIR,
        batch_size=1000  # Má»—i file 1000 documents
    )